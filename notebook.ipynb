{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import  RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from neo4j import GraphDatabase\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(file_path=\"dummytext.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=24)\n",
    "documents = text_splitter.split_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_type = os.getenv(\"LLM_TYPE\", \"openai\")\n",
    "if llm_type == \"ollama\":\n",
    "    llm = ChatOllama(model=\"llama3.1\", temperature=0)\n",
    "else:\n",
    "    llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphDocument(nodes=[Node(id='Amico’S Family', type='Family'), Node(id='Love', type='Concept'), Node(id='Tradition', type='Concept')], relationships=[Relationship(source=Node(id='Amico’S Family', type='Family'), target=Node(id='Love', type='Concept'), type='HAS'), Relationship(source=Node(id='Amico’S Family', type='Family'), target=Node(id='Tradition', type='Concept'), type='HAS')], source=Document(metadata={'source': 'dummytext.txt', 'id': 'ed648f5744c61a703b28736f1a7cf0c0'}, page_content='1. The Story of Amico’s Family: A Legacy of Love and Tradition'))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents,baseEntityLabel=True,include_source=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab9f052e13346f3977e66689057346d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def showGraph():\n",
    "    driver = GraphDatabase.driver(\n",
    "        uri=os.getenv(\"NEO4J_URI\"),\n",
    "        auth=(os.getenv(\"NEO4J_USERNAME\"), os.getenv(\"NEO4J_PASSWORD\"))\n",
    "    )\n",
    "    session = driver.session()\n",
    "    widget = GraphWidget(graph = session.run(\"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t\").graph())\n",
    "    widget.node_label_mapping = 'id'\n",
    "    return widget\n",
    "\n",
    "showGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    OpenAIEmbeddings(),\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "\n",
    "vector_retriever = vector_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities\"\"\"\n",
    "    names: list[str] = Field(..., description=\"All the person, organization, or business entities that appear in the text\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "[\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting organization and person entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "entity_chain = prompt | llm.with_structured_output(Entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nonna Lucia', 'Giovanni Caruso']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_chain.invoke({\"question\": \"Who are Nonna Lucia and Giovanni Caruso?\"}).names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_text_query(input: str) -> str:\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    if not words:\n",
    "        return \"\"\n",
    "    full_text_query = \" AND \".join([f\"{word}~2\" for word in words])\n",
    "    print(f\"Generated Query: {full_text_query}\")\n",
    "    return full_text_query.strip()\n",
    "\n",
    "\n",
    "# Fulltext index query\n",
    "def graph_retriever(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Collects the neighborhood of entities mentioned\n",
    "    in the question using MATCH queries directly.\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke({\"question\": question})\n",
    "    \n",
    "    for entity in entities.names:\n",
    "        print(f\"Entity: {entity}\")\n",
    "        response = graph.query(\n",
    "            \"\"\"\n",
    "            MATCH (n:Entity {id: $entity})\n",
    "            OPTIONAL MATCH (n)-[r:MENTIONS]->(neighbor)\n",
    "            RETURN n.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "            UNION\n",
    "            OPTIONAL MATCH (n)<-[r:MENTIONS]-(neighbor)\n",
    "            RETURN neighbor.id + ' - ' + type(r) + ' -> ' + n.id AS output\n",
    "            LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"entity\": entity}\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Nonna Lucia\n",
      "a7d2d246c8425014d3dca592ee8b298b - MENTIONS -> innovation\n",
      "a7d2d246c8425014d3dca592ee8b298b - MENTIONS -> tradition\n",
      "a7d2d246c8425014d3dca592ee8b298b - MENTIONS -> good food\n",
      "a7d2d246c8425014d3dca592ee8b298b - MENTIONS -> Caruso family\n",
      "a7d2d246c8425014d3dca592ee8b298b - MENTIONS -> Tradition\n",
      "a7d2d246c8425014d3dca592ee8b298b - MENTIONS -> Caruso Family\n",
      "a7d2d246c8425014d3dca592ee8b298b - MENTIONS -> Food\n",
      "a7d2d246c8425014d3dca592ee8b298b - MENTIONS -> Innovation\n",
      "a7d2d246c8425014d3dca592ee8b298b - MENTIONS -> Joy\n",
      "ed648f5744c61a703b28736f1a7cf0c0 - MENTIONS -> Amico’S Family\n",
      "ed648f5744c61a703b28736f1a7cf0c0 - MENTIONS -> Love\n",
      "ed648f5744c61a703b28736f1a7cf0c0 - MENTIONS -> Tradition\n",
      "da1344f72d2b4be3eec4f2c475251de2 - MENTIONS -> Santa Caterina\n",
      "da1344f72d2b4be3eec4f2c475251de2 - MENTIONS -> Caruso Family\n",
      "da1344f72d2b4be3eec4f2c475251de2 - MENTIONS -> Sicily\n",
      "608aa3cb5e0669d9328a2a6f161d768c - MENTIONS -> Love\n",
      "608aa3cb5e0669d9328a2a6f161d768c - MENTIONS -> Culinary Heritage\n",
      "608aa3cb5e0669d9328a2a6f161d768c - MENTIONS -> Family Member\n",
      "608aa3cb5e0669d9328a2a6f161d768c - MENTIONS -> Flavors\n",
      "608aa3cb5e0669d9328a2a6f161d768c - MENTIONS -> Experiences\n",
      "5129e243f8a852ffdc8d78bf45cdb788 - MENTIONS -> Food\n",
      "3d29be2f7e79f8b2f67f8e4f17cd95a7 - MENTIONS -> Giovanni Caruso\n",
      "3d29be2f7e79f8b2f67f8e4f17cd95a7 - MENTIONS -> Maria\n",
      "3d29be2f7e79f8b2f67f8e4f17cd95a7 - MENTIONS -> The Founding Generation\n",
      "ebcc965a447b44e84a2ba52cd829625c - MENTIONS -> Santa Caterina\n",
      "ebcc965a447b44e84a2ba52cd829625c - MENTIONS -> Giovanni Caruso\n",
      "70627865c96d4092aaaed601fc3ac04b - MENTIONS -> Maria\n",
      "70627865c96d4092aaaed601fc3ac04b - MENTIONS -> Giovanni\n",
      "0bd624cea747fde8fade2759d653c0ed - MENTIONS -> Love\n",
      "0bd624cea747fde8fade2759d653c0ed - MENTIONS -> Stews\n",
      "0bd624cea747fde8fade2759d653c0ed - MENTIONS -> Delicate Pastries\n",
      "0bd624cea747fde8fade2759d653c0ed - MENTIONS -> Ancestors\n",
      "0bd624cea747fde8fade2759d653c0ed - MENTIONS -> Culinary Experimentation\n",
      "0bd624cea747fde8fade2759d653c0ed - MENTIONS -> Children\n",
      "0bd624cea747fde8fade2759d653c0ed - MENTIONS -> Sicilian Kitchen\n",
      "442d38e82ff1de29c8842fcd2e0fb3bc - MENTIONS -> Antonio Caruso\n",
      "38ab29838c9b07411337b6525db63a00 - MENTIONS -> Maria\n",
      "38ab29838c9b07411337b6525db63a00 - MENTIONS -> Giovanni\n",
      "38ab29838c9b07411337b6525db63a00 - MENTIONS -> Antonio\n",
      "38ab29838c9b07411337b6525db63a00 - MENTIONS -> Eldest Son\n",
      "38ab29838c9b07411337b6525db63a00 - MENTIONS -> Village\n",
      "38ab29838c9b07411337b6525db63a00 - MENTIONS -> Island\n",
      "990b459f0c6ba04befdabc36776a7c7d - MENTIONS -> Antonio\n",
      "990b459f0c6ba04befdabc36776a7c7d - MENTIONS -> Village\n",
      "990b459f0c6ba04befdabc36776a7c7d - MENTIONS -> Sicilian Flavors\n",
      "990b459f0c6ba04befdabc36776a7c7d - MENTIONS -> Italy\n",
      "990b459f0c6ba04befdabc36776a7c7d - MENTIONS -> Weddings\n",
      "990b459f0c6ba04befdabc36776a7c7d - MENTIONS -> Grand Feasts\n",
      "91d5e0b1c1def50c7ed6156307b35edf - MENTIONS -> Grand Feasts\n",
      "91d5e0b1c1def50c7ed6156307b35edf - MENTIONS -> Dishes\n"
     ]
    }
   ],
   "source": [
    "print(graph_retriever(\"Who is Nonna Lucia?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_retriever(question: str):\n",
    "    graph_data = graph_retriever(question)\n",
    "    vector_data = [el.page_content for el in vector_retriever.invoke(question)]\n",
    "    final_data = f\"\"\"Graph data:\n",
    "{graph_data}\n",
    "vector data:\n",
    "{\"#Document \". join(vector_data)}\n",
    "    \"\"\"\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Use natural language and be concise.\n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "        {\n",
    "            \"context\": full_retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Amico's Family\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Amico\\'s Family is known for its rich culinary legacy rooted in love and tradition. They operate a restaurant called \"Amico\\'s\" in New York City, which offers a modern interpretation of Italian cuisine by blending traditional recipes with contemporary trends. The family is celebrated for creating grand feasts and innovative dishes that combine Sicilian and Tuscan flavors, establishing a signature style that reflects both nostalgia and innovation.'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input=\"I need a summary of Amico’s Family\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
